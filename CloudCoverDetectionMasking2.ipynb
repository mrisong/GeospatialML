{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrisong/GeospatialML/blob/main/CloudCoverDetectionMasking2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFp_7ZmrRMp-"
      },
      "outputs": [],
      "source": [
        "%pip install xarray\n",
        "%pip install xarray-spatial\n",
        "%pip install rasterio\n",
        "%pip install transformers\n",
        "%pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl5wJ7bvGUEz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import xarray\n",
        "import xrspatial.multispectral as ms\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "import time\n",
        "\n",
        "from typing import List\n",
        "from transformers import SegformerConfig, SegformerImageProcessor, SegformerForSemanticSegmentation\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "import torch.nn.utils.prune as prune\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvgQCosObg7p"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "data_dir = \"/content/gdrive/My Drive/CloudCoverData/\"\n",
        "feature_dir = f\"{data_dir}train_features/\"\n",
        "label_dir = f\"{data_dir}train_labels/\"\n",
        "\n",
        "meta_data = pd.read_csv(f\"{data_dir}train_metadata.csv\")\n",
        "\n",
        "bands = [\"B02\", \"B03\", \"B04\", \"B08\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anlysing the data"
      ],
      "metadata": {
        "id": "u6D7wxeTWZ6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meta_data.head()"
      ],
      "metadata": {
        "id": "hQ2C4KJGWb1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise how the chips vary by location\n",
        "train_location_counts = meta_data.groupby(\"location\")[\"chip_id\"].nunique().sort_values(ascending=False)\n",
        "\n",
        "# Since, the interest here is range of variation\n",
        "# I just choose the 10 locations with most and 10 locations with least number of chips\n",
        "location_counts_difference = pd.concat([train_location_counts[0:10], train_location_counts[-11:-1]])\n",
        "\n",
        "# Plot to visualise the same variation\n",
        "plt.figure(figsize=(12, 4))\n",
        "location_counts_difference.plot(kind=\"bar\")\n",
        "plt.xlabel(\"Location\")\n",
        "plt.ylabel(\"Number of chips\")\n",
        "plt.title(\"Distribution of number of chips over the top 10 and last 10 locations\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C72APtjWWjOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise how the chips vary by year\n",
        "# First separate the year from datetime stamp\n",
        "meta_data[\"datetime\"] = pd.to_datetime(meta_data[\"datetime\"])\n",
        "meta_data[\"year\"] = meta_data.datetime.dt.year\n",
        "\n",
        "# Group by the years\n",
        "train_time_counts = meta_data.groupby(\"year\")[\"chip_id\"].nunique().sort_index().reset_index(name ='chip_count')\n",
        "\n",
        "# Plot the distribution of number of chips with year\n",
        "plt.figure(figsize=(8, 4))\n",
        "train_time_counts['chip_count'].head(20).plot(kind=\"bar\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Number of chips\")\n",
        "plt.title(\"Distribution of number of chips over the years\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3JQFUGkwXjIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Location and time and number of chips\n",
        "chips_location_time = meta_data.groupby([\"location\", \"datetime\"])[[\"chip_id\"]].nunique().sort_values(by=\"chip_id\", ascending=False).rename(columns = {'chip_id' : 'chip_count'})\n",
        "chips_location_time.head(10)"
      ],
      "metadata": {
        "id": "nJ9Clt7gYJcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZpV2Ewin018"
      },
      "source": [
        "Looking at the meta data stored in some image.\n",
        "We note the image size here - 512Ã—512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X076GbnKnPxt"
      },
      "outputs": [],
      "source": [
        "with rasterio.open(f\"{feature_dir}jado/B02.tif\") as f:\n",
        "    meta = f.meta\n",
        "print(meta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfTnMlZzF5vu"
      },
      "outputs": [],
      "source": [
        "location_counts = meta_data.groupby(\"location\")[\"chip_id\"].nunique()\n",
        "# location_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiLfKbY5GCsI"
      },
      "outputs": [],
      "source": [
        "def add_paths(df, feature_dir, label_dir, bands=bands):\n",
        "  '''\n",
        "  add paths in the meta file corresponding to each chip\n",
        "  paths for the each band; and label for that chip is added\n",
        "  '''\n",
        "    for band in bands:\n",
        "        df[f\"{band}_path\"] = feature_dir + df['chip_id'] + f\"/{band}.tif\"\n",
        "\n",
        "    df[\"label_path\"] = label_dir + df['chip_id'] + \".tif\"\n",
        "  return df\n",
        "\n",
        "meta_data = add_paths(meta_data, feature_dir, label_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEkBYf0yIQnY"
      },
      "outputs": [],
      "source": [
        "# Functions to display True color images\n",
        "def make_DataArray(path):\n",
        "  img_array = np.array(Image.open(path))\n",
        "  return xarray.DataArray(img_array, dims = ['y', 'x'])\n",
        "\n",
        "def true_color_img(chip_id, data_path = feature_dir):\n",
        "  chip_path = f\"{data_path}{chip_id}/\"\n",
        "  red = make_DataArray(f\"{chip_path}B04.tif\")\n",
        "  green = make_DataArray(f\"{chip_path}B03.tif\")\n",
        "  blue = make_DataArray(f\"{chip_path}B02.tif\")\n",
        "  return ms.true_color(r=red, g=green, b=blue)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xbcetvrK8NU"
      },
      "outputs": [],
      "source": [
        "# Display random sample chips and the corresponding mask using the funcitons\n",
        "# in the previous cell\n",
        "\n",
        "fig = plt.figure(figsize=(25, 10))\n",
        "\n",
        "# display 5 images and masks\n",
        "no_of_chips = 5\n",
        "\n",
        "for i in range(1, no_of_chips+1):\n",
        "  # sample random chips\n",
        "    sample_chip = meta_data.sample().iloc[0]\n",
        "    ax = fig.add_subplot(2, no_of_chips, i)\n",
        "    ax.axis(\"off\")\n",
        "    ax.imshow(true_color_img(sample_chip.chip_id))\n",
        "    ax.set_title(f\"Chip Id: {sample_chip.chip_id}\\nLocation: {sample_chip.location}\")\n",
        "\n",
        "    ax = fig.add_subplot(2, 5, i+no_of_chips)\n",
        "    ax.axis(\"off\")\n",
        "    label = Image.open(sample_chip.label_path)\n",
        "    ax.imshow(label)\n",
        "    ax.set_title(f\"Chip Id {sample_chip.chip_id} label\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3-WQ06SUjNm"
      },
      "source": [
        "# Preparation for model fine-tuning\n",
        "The first step is to divide dataset into train, validation and test set.\n",
        "We will assign 30% of the data set as test data. From remaining 70%, 30% shall be validation data and rest all shall be training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK4y4KUCQj90"
      },
      "outputs": [],
      "source": [
        "print(f\"Total numbers of chips= {meta_data['chip_id'].count()}\")\n",
        "no_of_test_data = round(meta_data['chip_id'].count() * 0.3)\n",
        "print(f\"Number of chips in Test dataset = {no_of_test_data}\")\n",
        "no_of_validation_data = round(meta_data['chip_id'].count() * 0.7 * 0.3)\n",
        "print(f\"Number of chips in Validation dataset = {no_of_validation_data}\")\n",
        "print(f\"Number of chips in Train dataset= {meta_data['chip_id'].count()-no_of_test_data-no_of_validation_data}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE8KfVbjV18-"
      },
      "source": [
        "## Extracting the Test Data\n",
        "We attempt to divide the dataset based on the locations. Random locations are selected and total number of chips contribution from those locations are counted. The number of locations are increased in each loop. As soon as we get the required number of chips, break the loop and select the corresponding locations for the test data.\n",
        "\n",
        "Error and exception clause is used in this loop because it is possible that we don't get required number of chips as we keep on adding the locations. In such cases, we just restart from beginning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNhLpCEeXm6a"
      },
      "outputs": [],
      "source": [
        "test_meta = pd.DataFrame(columns=meta_data.columns)\n",
        "n_loc = 15\n",
        "iters = 0\n",
        "while True:\n",
        "    try:\n",
        "        random_locations = location_counts.sample(n=n_loc)\n",
        "        no_of_chips = np.sum(random_locations.to_numpy())\n",
        "        if no_of_chips in range(no_of_test_data-100, no_of_test_data+100):\n",
        "            print(f\"Number of Locations in the Test Dataset: {random_locations.count()}\")\n",
        "            print(f\"Total number of chips in the Test Dataset: {no_of_chips}\")\n",
        "            print(f\"Details of the selected locations:\\n{random_locations}\")\n",
        "            break\n",
        "        n_loc+=1\n",
        "    except ValueError:\n",
        "        n_loc=15\n",
        "        iters+=1\n",
        "        if iters == 20:\n",
        "            print(f\"Failed after {iters} iterations....\\nIncrease the range for total number of chips required in the test data\")\n",
        "            break\n",
        "        continue\n",
        "\n",
        "for i in random_locations.index:\n",
        "    next_row = meta_data.loc[meta_data.location == i, :]\n",
        "    test_meta = pd.concat([test_meta, next_row])\n",
        "    meta_data.drop(next_row.index, inplace=True)\n",
        "location_counts = meta_data.groupby(\"location\")[\"chip_id\"].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOZ8bbkeaTCR"
      },
      "source": [
        "## Extracting the Validation Data\n",
        "Same process is repeated for creating the validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mkNO_J4ZkYZ"
      },
      "outputs": [],
      "source": [
        "validation_meta = pd.DataFrame(columns=meta_data.columns)\n",
        "n_loc = 10\n",
        "iters = 0\n",
        "while True:\n",
        "    try:\n",
        "        random_locations = location_counts.sample(n=n_loc)\n",
        "        no_of_chips = np.sum(random_locations.to_numpy())\n",
        "        if no_of_chips in range(no_of_validation_data-100, no_of_validation_data+100):\n",
        "            print(f\"Number of Locations in the Validation Dataset: {random_locations.count()}\")\n",
        "            print(f\"Total number of chips in the Validation Dataset: {no_of_chips}\")\n",
        "            print(f\"Details of the selected locations:\\n{random_locations}\")\n",
        "            break\n",
        "        n_loc+=1\n",
        "    except ValueError:\n",
        "        n_loc=10\n",
        "        iters+=1\n",
        "        if iters == 20:\n",
        "            print(f\"Failed after {iters} iterations....\\nIncrease the range for total number of chips required in the test data\")\n",
        "            break\n",
        "        continue\n",
        "\n",
        "for i in random_locations.index:\n",
        "    next_row = meta_data.loc[meta_data.location == i, :]\n",
        "    validation_meta = pd.concat([validation_meta, next_row])\n",
        "    meta_data.drop(next_row.index, inplace=True)\n",
        "location_counts = meta_data.groupby(\"location\")[\"chip_id\"].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEV6TsBqhDeY"
      },
      "source": [
        "## The Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q12qTLwsgmjR"
      },
      "outputs": [],
      "source": [
        "print(f\"Number of Locations in the Training Dataset: {location_counts.count()}\")\n",
        "print(f\"Total number of chips in the Training Dataset: {np.sum(location_counts.to_numpy())}\")\n",
        "print(f\"Details of the selected locations:\\n{location_counts}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4fersBOh_kM"
      },
      "source": [
        "Summary of number of data points in each dataset after the train-validate-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYzZEOQliODX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83ccb5f8-e530-4b92-ac07-1019135a1a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data: 5830(49.63%)\n",
            "Validation data: 2494(21.23%)\n",
            "Test data: 3424(29.15%)\n"
          ]
        }
      ],
      "source": [
        "total = len(meta_data)+len(validation_meta)+len(test_meta)\n",
        "print(f\"Training data: {len(meta_data)}({round(len(meta_data)*100/total, 2)}%)\")\n",
        "print(f\"Validation data: {len(validation_meta)}({round(len(validation_meta)*100/total, 2)}%)\")\n",
        "print(f\"Test data: {len(test_meta)}({round(len(test_meta)*100/total, 2)}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkuPIgHOrYYJ"
      },
      "source": [
        "## Creating Dataset\n",
        "Create custom Dataset by importing PyTorch Dataset class for further processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ed-W4k64rXhK"
      },
      "outputs": [],
      "source": [
        "class CloudDataset(Dataset):\n",
        "  def __init__(self, data_df: pd.DataFrame,\n",
        "               bands: List[str]=bands):\n",
        "    '''\n",
        "    Construct Dataset type class\n",
        "    '''\n",
        "    self.data = data_df\n",
        "    self.bands = bands\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx: int):\n",
        "    img = self.data.loc[idx]\n",
        "    band_stack = []\n",
        "    for band in self.bands:\n",
        "      with rasterio.open(img[f\"{band}_path\"]) as b:\n",
        "        next_band = b.read(1).astype(\"float32\")\n",
        "      band_stack.append(next_band)\n",
        "\n",
        "    feature_array = np.stack(band_stack, axis = -1)\n",
        "    feature_array = np.transpose(feature_array, [2, 0, 1])\n",
        "\n",
        "    l_path = self.data.loc[idx].label_path\n",
        "    with rasterio.open(l_path) as l:\n",
        "      label_array = l.read(1).astype(\"float32\")\n",
        "\n",
        "    item = {\"chip_id\": img.chip_id,\n",
        "            \"image\": feature_array,\n",
        "            \"label\": label_array}\n",
        "    return item"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modify the pre-trained model\n",
        "Update the number of input channels from 3 to 4 - consistent with the available dataset"
      ],
      "metadata": {
        "id": "iwESb6mGACur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modifiedSegformer():\n",
        "  n_channels = 4\n",
        "\n",
        "  # Get pretrained model\n",
        "  segformer_model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
        "\n",
        "  # Copy the configuration of pretrained model\n",
        "  new_config = segformer_model.config\n",
        "\n",
        "  # Modify config's values\n",
        "  new_config.num_channels=n_channels\n",
        "\n",
        "  # Instantiate new (randomly initialized) model\n",
        "  new_model = SegformerForSemanticSegmentation(new_config)\n",
        "\n",
        "  #Substitute first layer of the pretrained model with the modified one\n",
        "  segformer_model.segformer.encoder.patch_embeddings[0] = new_model.segformer.encoder.patch_embeddings[0]\n",
        "\n",
        "  return segformer_model.to(device)"
      ],
      "metadata": {
        "id": "Jp-AL9XKI5_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation functions"
      ],
      "metadata": {
        "id": "uYhNkjeKAo4J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyERQdn95EWW"
      },
      "outputs": [],
      "source": [
        "def training(model, n_epochs=10, mode='Validation'):\n",
        "  '''\n",
        "  The training loop...\n",
        "  Training using Dataloader class of PyTorch.\n",
        "  Also using Automatis Mixed Precision for increasing training speed\n",
        "  '''\n",
        "  model.train()\n",
        "\n",
        "  since = time.time()\n",
        "  print(\"\\n\\n*************Model Training*************\\n\\n\")\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    print(f\"-----------Epoch: {epoch}-----------\")\n",
        "    for idx, batch in enumerate(trainDataloader):\n",
        "\n",
        "      # Training each batch in this loop\n",
        "      x = batch[\"image\"].to(device)\n",
        "      y = batch[\"label\"].long().to(device)\n",
        "\n",
        "      # Computationally efficient operation compared to 'optimizer.zero_grad()'\n",
        "      # as per 'https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html'\n",
        "      optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "      with torch.autocast(device_type=device, dtype=autocastType, enabled=ifcuda):\n",
        "        outputs = model(x, y)\n",
        "        loss, logits = outputs[0], outputs[1]\n",
        "      scaler.scale(loss).backward()\n",
        "      scaler.step(optimizer)\n",
        "      scaler.update()\n",
        "\n",
        "      print(f\"Batch Number: {idx+1}\")\n",
        "      print(f'loss: {loss.item()}')\n",
        "\n",
        "    # Run validation every second epoch; this may be increased if more number of epochs are run\n",
        "    if epoch % 2 == 0 and mode == 'Validation':\n",
        "      evaluation(model, evalDataloader = valDataloader, mode = mode)\n",
        "  print(f\"\\n\\nTraining time: {time.time()-since}s\")\n",
        "  print(\"\\n\\n*************Training Complete*************\\n\\n\")\n",
        "  return model\n",
        "\n",
        "def evaluation(model, evalDataloader, mode = \"Test\"):\n",
        "  global best_acc\n",
        "  model.eval()\n",
        "\n",
        "  print(\"\\n\\n*************Model Evaluation*************\\n\\n\")\n",
        "  with torch.no_grad():\n",
        "    total_loss = 0\n",
        "    for idx, batch in enumerate(evalDataloader):\n",
        "      x = batch[\"image\"].to(device)\n",
        "      y = batch[\"label\"].long().to(device)\n",
        "\n",
        "      outputs = model(x, y)\n",
        "      loss, logits = outputs[0], outputs[1]\n",
        "\n",
        "      total_loss += loss.item()\n",
        "      upsampled_logits = nn.functional.interpolate(\n",
        "                      logits,\n",
        "                      size=y.shape[-2:],\n",
        "                      mode=\"bilinear\",\n",
        "                      align_corners=False\n",
        "                  )\n",
        "\n",
        "      predicted = upsampled_logits.argmax(dim=1)\n",
        "\n",
        "      predictions=predicted.detach().cpu().numpy()\n",
        "      references=y.detach().cpu().numpy()\n",
        "\n",
        "      test_mean_iou.add_batch(\n",
        "        predictions=predictions,\n",
        "        references=references\n",
        "      )\n",
        "\n",
        "    metrics = test_mean_iou.compute(num_labels=2, ignore_index=255)\n",
        "    mean_loss = total_loss/len(testDataloader)\n",
        "    print(f'{mode} loss: {mean_loss}\\t\\tMean IOU: {metrics[\"mean_iou\"]}\\t\\tMean Accuracy: {metrics[\"mean_accuracy\"]}')\n",
        "\n",
        "  if mode == 'Test':\n",
        "    pass\n",
        "  elif best_acc < metrics[\"mean_accuracy\"]:\n",
        "    best_acc = metrics[\"mean_accuracy\"]\n",
        "  print(\"\\n\\n*************Evaluation Complete*************\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pruning Function - Apply 50% network pruning, to increase the training speed"
      ],
      "metadata": {
        "id": "GXzvzAE73a8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_prune(model):\n",
        "  # The following modules conatin 'weight' parameter, thus, may be pruned\n",
        "  parameters_to_prune = [(model.segformer.encoder.patch_embeddings[0].proj, 'weight'),\n",
        "  (model.segformer.encoder.patch_embeddings[1].proj, 'weight'),\n",
        "  (model.segformer.encoder.patch_embeddings[2].proj, 'weight'),\n",
        "  (model.segformer.encoder.patch_embeddings[3].proj, 'weight'),\n",
        "  (model.segformer.encoder.patch_embeddings[0].layer_norm, 'weight'),\n",
        "  (model.segformer.encoder.patch_embeddings[1].layer_norm, 'weight'),\n",
        "  (model.segformer.encoder.patch_embeddings[2].layer_norm, 'weight'),\n",
        "  (model.segformer.encoder.patch_embeddings[3].layer_norm, 'weight')]\n",
        "\n",
        "# Loop is used because these modules are available in different layer\n",
        "# By just changing the index number we can assecc these modules and their 'weight' parameters\n",
        "  for j in range(2):\n",
        "    for k in range(3):\n",
        "      parameters_to_prune += [(model.segformer.encoder.block[k][j].attention.self.sr, 'weight'),\n",
        "      (model.segformer.encoder.block[k][j].attention.self.layer_norm, 'weight')]\n",
        "    for i in range(4):\n",
        "      parameters_to_prune += [(model.segformer.encoder.block[i][j].layer_norm_1, 'weight'),\n",
        "      (model.segformer.encoder.block[i][j].attention.self.query, 'weight'),\n",
        "      (model.segformer.encoder.block[i][j].attention.self.key, 'weight'),\n",
        "      (model.segformer.encoder.block[i][j].attention.self.value, 'weight'),\n",
        "      (model.segformer.encoder.block[i][j].attention.output.dense, 'weight'),\n",
        "      (model.segformer.encoder.block[i][j].layer_norm_2, 'weight'),\n",
        "      (model.segformer.encoder.block[i][j].mlp.dense1, 'weight'),\n",
        "      (model.segformer.encoder.block[i][j].mlp.dwconv.dwconv, 'weight'),\n",
        "      (model.segformer.encoder.block[i][j].mlp.dense2, 'weight')]\n",
        "\n",
        "  parameters_to_prune = tuple(parameters_to_prune)\n",
        "\n",
        "  prune.global_unstructured(\n",
        "      parameters_to_prune,\n",
        "      pruning_method=prune.L1Unstructured,\n",
        "      amount = 0.5\n",
        "  )\n",
        "  # print(model.segformer.encoder.block[i][j].mlp.dense2._forward_pre_hooks)"
      ],
      "metadata": {
        "id": "cUUHIr9x_z9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the Dataset and Dataloder"
      ],
      "metadata": {
        "id": "bwVg6DYnAvvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Because of resource constraint, currently using only 200 images for training, 120 for validation and 80 for test\n",
        "trainDataset = CloudDataset(data_df = meta_data.reset_index(drop=True)[0:200],\n",
        "                            bands = bands)\n",
        "valDataset = CloudDataset(data_df = validation_meta.reset_index(drop=True)[0:120],\n",
        "                          bands = bands)\n",
        "testDataset = CloudDataset(data_df = test_meta.reset_index(drop=True)[0:80],\n",
        "                          bands = bands)\n",
        "\n",
        "batch_size = 8\n",
        "trainDataloader = DataLoader(trainDataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "valDataloader = DataLoader(valDataset, batch_size=batch_size, num_workers=2)\n",
        "testDataloader = DataLoader(testDataset, batch_size=batch_size, num_workers=2)"
      ],
      "metadata": {
        "id": "waGSYbMpJZFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define model, update the available device and define the evaluation metrics."
      ],
      "metadata": {
        "id": "E1Ft9671A1n8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device, ifcuda, autocastType = (\"cuda\", True, torch.float16) if torch.cuda.is_available() else (\"cpu\", False, torch.bfloat16)\n",
        "model = modifiedSegformer()\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=ifcuda)\n",
        "\n",
        "hypr_params = {\"learning_rate\": 0.0001,\n",
        "               \"optimizer\": optim.SGD\n",
        "               }\n",
        "\n",
        "n_epochs = 5\n",
        "train_mean_iou = evaluate.load(\"mean_iou\")\n",
        "val_mean_iou = evaluate.load(\"mean_iou\")\n",
        "test_mean_iou = evaluate.load(\"mean_iou\")"
      ],
      "metadata": {
        "id": "-KK7oGPI-uEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Validation\n",
        "Hyper-parameter tuning shall be performed as follows. It is demonstrated for learning rate and optimizer, but shall be extended for other hyper-parameters in future."
      ],
      "metadata": {
        "id": "kl8gpPjH_D4j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hT0Rw7LwVRTa"
      },
      "outputs": [],
      "source": [
        "# Tuning the learning rate using validation\n",
        "best_acc = 0\n",
        "print(\"Tuning the learning rate.....\")\n",
        "for hypr_params[\"learning_rate\"] in [0.001, 0.0001]:\n",
        "  print(f\"learning rate = {hypr_params['learning_rate']}\")\n",
        "  ref_acc = best_acc\n",
        "  model = modifiedSegformer()\n",
        "  optimizer = hypr_params['optimizer'](model.parameters(), lr=hypr_params[\"learning_rate\"], momentum=0.9)\n",
        "  model_prune(model)\n",
        "  trained_model = training(model, n_epochs)\n",
        "  if best_acc > ref_acc:\n",
        "    best_param = hypr_params[\"learning_rate\"]\n",
        "\n",
        "hypr_params[\"learning_rate\"] = best_param\n",
        "print(f\"The best of the tested learning rate is: {best_param}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only Adam is used here currently, but it may be easily extended to other optimizers."
      ],
      "metadata": {
        "id": "lXSUTDc9Smob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning the Optimizer using validation\n",
        "\n",
        "best_acc = 0\n",
        "best_param = hypr_params[\"optimizer\"]\n",
        "print(\"Tuning the Optimizer.....\")\n",
        "for hypr_params[\"optimizer\"] in [optim.Adam]: #Add optimizer names in this list, to validate the model against\n",
        "  print(f\"Optimizer = {hypr_params['optimizer'].__name__}\")\n",
        "  ref_acc = best_acc\n",
        "  model = modifiedSegformer()\n",
        "  optimizer = hypr_params['optimizer'](model.parameters(), lr=hypr_params[\"learning_rate\"])\n",
        "  model_prune(model)\n",
        "  trained_model = training(model, n_epochs)\n",
        "\n",
        "  if best_acc > ref_acc:\n",
        "    best_param = hypr_params[\"optimizer\"]\n",
        "\n",
        "hypr_params[\"optimizer\"] = best_param\n",
        "print(f\"The best of the tested optimizer is: {best_param.__name__}\")"
      ],
      "metadata": {
        "id": "SA8RztygrhHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training\n",
        "Best model found through validatino is now trained"
      ],
      "metadata": {
        "id": "QUCcT2QKynao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Because of resource constraint, currently using only 320 images shall be used for training - 200 from training set, 120 from validation set\n",
        "trainDataset = CloudDataset(data_df = pd.concat([meta_data.reset_index(drop=True)[0:200], validation_meta.reset_index(drop=True)[0:120]], ignore_index=True),\n",
        "                            bands = bands)\n",
        "\n",
        "batch_size = 8\n",
        "trainDataloader = DataLoader(trainDataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "model = modifiedSegformer()\n",
        "\n",
        "# Assign the optimizer with model parameter\n",
        "optimizer = hypr_params['optimizer'](model.parameters(), lr=hypr_params[\"learning_rate\"])\n",
        "\n",
        "# If the optimizer is SGD, assign the momentum value also. This itself is a tunable paramter, which may be attempted in future\n",
        "if hypr_params['optimizer'].__name__ == 'SGD':\n",
        "  optimizer.momentum = 0.9\n",
        "\n",
        "# Prune the model\n",
        "model_prune(model)\n",
        "\n",
        "# Now, the model is ready to be trained\n",
        "trained_model = training(model, n_epochs, 'Train')"
      ],
      "metadata": {
        "id": "K7kKoet9yonz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Evaluation"
      ],
      "metadata": {
        "id": "GPSJE4UQ_HkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(trained_model, evalDataloader=testDataloader)"
      ],
      "metadata": {
        "id": "jr0UGhlN_IWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantization\n",
        "Apply Eager Mode, Post-Training, Dynamic Quantization"
      ],
      "metadata": {
        "id": "jTRMmT3u_Rfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.ao.quantization.quantize_fx as quantize_fx\n",
        "from torch.ao.quantization import QConfigMapping\n",
        "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
        "import os"
      ],
      "metadata": {
        "id": "j_UteVAj_M92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_to_quantize = trained_model.to(\"cpu\")\n",
        "model_quantised = torch.ao.quantization.quantize_dynamic(\n",
        "    model_to_quantize,  # the original model\n",
        "    {torch.nn.Linear},  # a set of layers to dynamically quantize\n",
        "    dtype=torch.qint8)"
      ],
      "metadata": {
        "id": "Zl3-ykaR_iR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the size of the quantized model with the original trained model"
      ],
      "metadata": {
        "id": "WwXH-JCwB5sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_size_of_model(model, label=\"\"):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    size=os.path.getsize(\"temp.p\")\n",
        "    print(f\"model: {label}\\t Size (KB): {size/1e3})\n",
        "    os.remove('temp.p')\n",
        "    return size\n",
        "\n",
        "# compare the sizes\n",
        "f=print_size_of_model(model_to_quantize,\"fp32\")\n",
        "q=print_size_of_model(model_int8,\"int8\")\n",
        "\n",
        "print(f\"{f/q} times smaller\")"
      ],
      "metadata": {
        "id": "br29aV_yYL0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following method is tried to quantized and deploy a lite version. But it is currently not supported by Pytorch"
      ],
      "metadata": {
        "id": "70Ey5CWPR_Vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_to_quantize = trained_model.to(\"cpu\")\n",
        "model_to_quantize.eval()\n",
        "scripted_model = torch.jit.script(model_to_quantize)\n",
        "scripted_model.save(\"segformer_cloud_script.pt\")\n",
        "\n",
        "\n",
        "backend = \"qnnpack\"\n",
        "model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
        "torch.backends.quantized.engine = backend\n",
        "\n",
        "quantized_model = torch.quantization.quantize_dynamic(model_to_quantize, qconfig_spec={torch.nn.Linear}, dtype=torch.qint8)\n",
        "scripted_quantized_model = torch.jit.script(quantized_model)\n",
        "scripted_quantized_model.save(\"segformer_cloud_quantized_script.pt\")"
      ],
      "metadata": {
        "id": "MYZIz-wuZGKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "scripted_quantized_model = torch.jit.script(model_int8)\n",
        "scripted_quantized_model.save(\"segformer_cloud_quantized_script.pt\")\n",
        "\n",
        "optimized_scripted_quantized_model = optimize_for_mobile(scripted_quantized_model)\n",
        "optimized_scripted_quantized_model.save(\"segformer_cloud_optimized_quantized_script.pt\")"
      ],
      "metadata": {
        "id": "sM7IIBAqaC1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_scripted_quantized_model._save_for_lite_interpreter(\"segformer_cloud_optimized_quantized_script_lite.ptl\")\n",
        "ptl = torch.jit.load(\"segformer_cloud_optimized_quantized_script_lite.ptl\")"
      ],
      "metadata": {
        "id": "QXRFMPSCaPUF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFWI9vm4MQw9t3XJyW2bDi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}